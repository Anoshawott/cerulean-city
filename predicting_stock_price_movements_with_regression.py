# -*- coding: utf-8 -*-
"""Predicting Stock Price Movements with Regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z9PWNmWTKmQiW9BVVbXO46djXBX8PiTE

# Data Analytics
## Stock predictions

First exploring and understanding the stock datasets these will lead onto prediction analysis using:

*   Simple linear analysis
*   Quadratic Linear Analysis (QDA)
*   K Nearest Neighbor (KNN)

This project applies pandas and its web data reader to communicate with the most updated financial data.
"""

import pandas as pd
import datetime
import pandas_datareader.data as web
from pandas import Series, DataFrame

start = datetime.datetime(2010, 1, 1)
end = datetime.datetime.now()

df = web.DataReader("GOOG", "yahoo", start, end)
df.tail(5)

df.shape

"""The following calculates a rolling mean (moving average), simplifying price data."""

close_px = df['Adj Close']
mavg = close_px.rolling(window = 100).mean()
mavg.tail(10)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 
import matplotlib.pyplot as plt
from matplotlib import style

#Size of matplotlib
import matplotlib as mpl
mpl.rc('figure', figsize = (8, 7))
mpl.__version__

#Style of matplotlib
style.use('ggplot')

close_px.plot(label = 'GOOG')
mavg.plot(label = 'mavg')
plt.legend()

"""Here we define the returns made at the closing price."""

rets = close_px / close_px.shift(1) - 1
rets.head(5)

#otherwise a quicker way is close_px.pct_change().head()

rets.plot(label = 'return')

"""Now we are going to assess the correlations amongst different companies and how their stock prices move with respect to one another."""

dfcomp = web.DataReader(['AAPL', 'MSFT', 'IBM', 'TEAM', 'GOOG'], 'yahoo', start = start, end = end)['Adj Close']
dfcomp.tail(5)

dfcomp.shape

retscomp = round(dfcomp.pct_change(), 4)

corr = retscomp.corr()
corr

plt.scatter(retscomp.TEAM, retscomp.GOOG)
plt.xlabel('Returns TEAM')
plt.ylabel('Returns GOOG')

"""Completing a scatter matrix amongst the competitors selected above we can find the kernel density estimation (KDE) of each company. A normal distribution that is shifted more to the left is more likely negative in the long run while to the right is more likely positive. The centre are more likely 0."""

from pandas.plotting import scatter_matrix
scatter_matrix(retscomp, diagonal = 'kde', figsize = (10, 10));

plt.imshow(corr, cmap = 'hot', interpolation = 'none')
plt.colorbar()
plt.xticks(range(len(corr)), corr.columns)
plt.yticks(range(len(corr)), corr.columns);

"""Assessing through kurtosis and skewness we will now determine the level of risk associated with each stock."""

plt.scatter(retscomp.mean(), retscomp.std())
plt.xlabel('Expected returns')
plt.ylabel('Risk')
for label, x, y in zip(retscomp.columns, retscomp.mean(), retscomp.std()):
  plt.annotate(
      label,
      xy = (x, y ), xytext = (20, -20),
      textcoords = 'offset points', ha = 'right', va = 'bottom',
      bbox = dict(boxstyle = 'round,pad = 0.5', fc = 'yellow', alpha = 0.5), 
      arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0')
  )

"""Applying simple linear analysis, quadratic linear analysis (QDA) and K-Nearest Neighbour (KNN) models the following will produce predictions on stock price movements."""

dfreg = df.loc[:,['Adj Close', 'Volume']]
dfreg['HL_PCT'] = (df['High'] - df['Low']) / df['Close'] * 100.0
dfreg['PCT_change'] = (df['Close'] - df['Open']) / df['Open'] * 100.0
print(dfreg.head())

#Another table for the Quadratic prediction model
dfreg1 = df.loc[:,['Adj Close', 'Volume']]
dfreg1['HL_PCT'] = (df['High'] - df['Low']) / df['Close'] * 100.0
dfreg1['PCT_change'] = (df['Close'] - df['Open']) / df['Open'] * 100.0

#Another table for the KNN prediction model
dfreg2 = df.loc[:,['Adj Close', 'Volume']]
dfreg2['HL_PCT'] = (df['High'] - df['Low']) / df['Close'] * 100.0
dfreg2['PCT_change'] = (df['Close'] - df['Open']) / df['Open'] * 100.0

import math
import numpy as np
from sklearn import preprocessing, svm
from sklearn.model_selection import cross_validate


# Drop missing value
dfreg.fillna(value = -99999, inplace = True)

print(dfreg.shape)
# We want to separate 1 percent of the data to forecast
forecast_out = int(math.ceil(0.01 * len(dfreg)))

#Separating the label here, we want to predict the AdjClose
forecast_col = 'Adj Close'
dfreg['label'] = dfreg[forecast_col].shift(-forecast_out)
X = np.array(dfreg.drop(['label'],1))

#Scale the X so that everyone can have the same distribution for linear regression
X = preprocessing.scale(X)

#Finally We want to find Data Series of Late X and early X (train) for model generation and evaluation
X_lately = X[-forecast_out:]
X = X[:-forecast_out]

#Separate label and identify it as y
y = np.array(dfreg['label'])
y = y[:-forecast_out]

print('Dimension of X', X.shape)
print('Dimension of y', y.shape)

#Quadratic model

# Drop missing value
dfreg1.fillna(value = -99999, inplace = True)

# We want to separate 1 percent of the data to forecast
forecast_out1 = int(math.ceil(0.01 * len(dfreg1)))

#Separating the label here, we want to predict the AdjClose
forecast_col1 = 'Adj Close'
dfreg1['label'] = dfreg1[forecast_col1].shift(-forecast_out1)
X1 = np.array(dfreg1.drop(['label'],1))

#Scale the X so that everyone can have the same distribution for linear regression
X1 = preprocessing.scale(X1)

#Finally We want to find Data Series of Late X and early X (train) for model generation and evaluation
X_lately1 = X1[-forecast_out1:]
X1 = X1[:-forecast_out1]

#Separate label and identify it as y
y1 = np.array(dfreg1['label'])
y1 = y1[:-forecast_out1]

#KNN model

# Drop missing value
dfreg2.fillna(value = -99999, inplace = True)

# We want to separate 1 percent of the data to forecast
forecast_out2 = int(math.ceil(0.01 * len(dfreg2)))

#Separating the label here, we want to predict the AdjClose
forecast_col2 = 'Adj Close'
dfreg2['label'] = dfreg2[forecast_col2].shift(-forecast_out2)
X2 = np.array(dfreg2.drop(['label'],1))

#Scale the X so that everyone can have the same distribution for linear regression
X2 = preprocessing.scale(X2)

#Finally We want to find Data Series of Late X and early X (train) for model generation and evaluation
X_lately2 = X2[-forecast_out2:]
X2 = X2[:-forecast_out2]

#Separate label and identify it as y
y2 = np.array(dfreg2['label'])
y2 = y2[:-forecast_out2]

from sklearn.model_selection import train_test_split
#Separation of training and testing of model by cross validatoin train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

#Similarly for the other two models
#Quadratic

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2)

#KNN
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.2)

"""Producing the model:"""

from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor

from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

#Linear regression
clfreg = LinearRegression(n_jobs = -1)
clfreg.fit(X_train, y_train)

#Quadratic Regression 2
clfpoly2 = make_pipeline(PolynomialFeatures(2), Ridge())
clfpoly2.fit(X_train, y_train)

#Quadratic Regression 3
clfpoly3 = make_pipeline(PolynomialFeatures(3), Ridge())
clfpoly3.fit(X1_train, y1_train)

#KNN Regression
clfknn = KNeighborsRegressor(n_neighbors = 2)
clfknn.fit(X2_train, y2_train)

"""Testing the model."""

confidencereg = clfreg.score(X_test, y_test)
confidencepoly2 = clfpoly2.score(X_test, y_test)
confidencepoly3 = clfpoly3.score(X1_test, y1_test)
confidenceknn = clfknn.score(X2_test, y2_test)

print("The linear regression confidence is", confidencereg)
print("The quadratic regression 2 confidence is ", confidencepoly2)
print("The quadratic regression 3 confidence is ", confidencepoly3)
print("The knn regression confidence is ", confidenceknn)

"""The results above imply that the quadratic regression 3 holds the most accurate.

Price trajectories vary from company and hence must be considered. To understand this better we will produce a plot of these predictions.
"""

forecast_set = clfreg.predict(X_lately)
dfreg['Forecast'] = np.nan
print(forecast_set, confidencereg, forecast_out)

forecast_set1 = clfpoly3.predict(X_lately)
dfreg1['Forecast'] = np.nan
print(forecast_set1, confidencepoly3, forecast_out1)

forecast_set2 = clfknn.predict(X_lately)
dfreg2['Forecast'] = np.nan
print(forecast_set2, confidenceknn, forecast_out2)

last_date = dfreg.iloc[-1].name
last_unix = last_date
next_unix = last_unix + datetime.timedelta(days = 1)

for i in forecast_set:
  next_date = next_unix
  next_unix += datetime.timedelta(days=1)
  dfreg.loc[next_date] = [np.nan for _ in range(len(dfreg.columns)-1)]+[i]

dfreg['Adj Close'].tail(28).plot()
dfreg['Forecast'].tail(28).plot()
plt.legend(loc = 4)
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Linear Regression Model Predictions of GOOG Prices')
plt.show()

last_date = dfreg1.iloc[-1].name
last_unix = last_date
next_unix = last_unix + datetime.timedelta(days = 1)

for i in forecast_set1:
  next_date = next_unix
  next_unix += datetime.timedelta(days=1)
  dfreg1.loc[next_date] = [np.nan for _ in range(len(dfreg1.columns)-1)]+[i]

dfreg1['Adj Close'].tail(28).plot()
dfreg1['Forecast'].tail(28).plot()
plt.legend(loc = 4)
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Quadratic Regression Model Predictions of GOOG Prices')
plt.show()

last_date = dfreg2.iloc[-1].name
last_unix = last_date
next_unix = last_unix + datetime.timedelta(days = 1)

for i in forecast_set2:
  next_date = next_unix
  next_unix += datetime.timedelta(days=1)
  dfreg2.loc[next_date] = [np.nan for _ in range(len(dfreg2.columns)-1)]+[i]

dfreg2['Adj Close'].tail(28).plot()
dfreg2['Forecast'].tail(28).plot()
plt.legend(loc = 4)
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('KNN Regression Model Predictions of GOOG Prices')
plt.show()